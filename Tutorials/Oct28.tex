\documentclass[10pt]{article}
\usepackage{epsfig}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsfonts}
\usepackage{graphicx}
\addtolength{\oddsidemargin}{-.750in}% Controls page offset - Left
\addtolength{\voffset}{-.125in}      % Controls page offset - Top
\addtolength{\textwidth}{1.0in}      % Controls Text width
\addtolength{\textheight}{1.125in}       % Controls Text height
\renewcommand{\baselinestretch}{1} % Controls line spacing
\renewcommand{\thefootnote}{\fnsymbol{footnote}}


\title {\sc Stopping times, Random walks, Bernoulli processes - Some exercises}
\author{$E2-202$ - Random Processes, Fall $2017$, ECE, IISc.\\Prepared by - Karthik and Sahasranand}
\date{October 28, 2017}

\begin{document}
\maketitle 
\begin{enumerate}
	\item Prove:
	\begin{enumerate}
		\item (\emph{Adam's law})
		\[
		E[X] = E\left[E[X|Y]\right].
		\]
		\item (\emph{Eve's law})
		\[
		\text{Var}(X)  = E\left[\text{Var}(X|Y)\right] + \text{Var}\left(E[X|Y]\right),
		\]
		where $\text{Var}(X|Y)=E[(X-E[X|Y])^{2}|Y]$.
	\end{enumerate}

\item Suppose $\{\mathcal{F}_n: n \in \mathbb{N}\}$ is a filtration and $Y_n$ is measurable with respect to $\mathcal{F}_n$. Let $N$ be a stopping time with respect to this filtration. Show that $Y_N$ is measurable with respect to $\mathcal{F}_N$ 

\emph{Note: Here, $\mathcal{F}_{N}$ denotes the stopping time $\sigma$-algebra. Use its definition to solve the problem.}

\item Let $(X_n)_{n\geq 1}$ be a Markov process on the state space $\mathcal{S}=\{0,1\}$. Associated with the process $(X_n)_{n\geq 1}$, consider the natural filtration $\mathcal{F}_{n}=\sigma(X_{1},\ldots,X_{n})$, $n\geq 1$. Define
\begin{equation*}
N:=\inf\{n\geq 1:X_{n+1}=1\}.
\end{equation*}
Assume that $P(N<\infty)=1$.
\begin{enumerate}
	\item Is $N$ a stopping time with respect to $(\mathcal{F}_{n})_{n\geq 1}$? Justify your answer.
	\item Show that $(X_{n})_{n\geq 1}$ fails to satisfy the strong Markov property with $N$.
\end{enumerate}

\item Let $(X_i: i \in \mathbb{N})$ be iid with $E|X_1| < \infty$ and $S_n = \sum_{i=1}^n X_i$.
\begin{enumerate}
	\item Show that 
	\[
	ES_n = n\cdot EX_1.
	\]
	\item Let $N$ be a random variable taking values in $\mathbb{N}$ with $EN < \infty$ and $N$ be independent of $X_i$s.  Show that
	\[
	ES_N = EN \cdot EX_1.
	\]
	\item Let $X_i \sim \text{Geo}(p)$ and $N \sim \text{Geo}(q)$ be a stopping time with respect to the process $(X_i: i \in \mathbb{N})$. Show that
	\[
	ES_N = \frac{1}{pq}.
	\]
\end{enumerate}

\item Consider an iid sequence $(X_n)_{n\geq 1}$ with each $X_{n}$ being uniformly distributed over the set $\{1,2,\ldots,10\}$. Think of $X_{1}$ as the bonus (in units of INR $10000$) given at the end of first year, $X_{2}$ as the bonus given at the end of second year, and so on. Define $N$ to be the first time a bonus of $7$ is obtained, i.e.,
\begin{equation*}
N:=\inf\{n\geq 1:X_{n}=7\}.
\end{equation*}
Compute the expected total bonus received up to time $N$. 

\item Let $X_{1},X_{2},\ldots$ be iid uniform on $(0,1)$. For each $n\geq 1$, let $S_{n}=X_{1}+\cdots+X_{n}$. Define
\begin{equation*}
N:=\inf\{n\geq 1:X_{n}>X_{n-1}\}.
\end{equation*}
\begin{enumerate}
	\item Show that $P(N>n)=\frac{1}{n!}$.
	\item Compute $E[S_{N}]$.
\end{enumerate}

\item (\emph{Gambler's ruin}) Two players $A$ and $B$ play a game with independent rounds where, in each round, one
of the players wins $ \$ 1 $  from his opponent; $ A $ wins with probability $ p $ and $ B $ wins with probability $ q = 1 - p $. \underline{$ A $ starts the game} with $ \$a $  and $ B $ with $ \$b $. The game ends when one of the players is ruined (i.e., the player's earnings becomes $0$).

\emph{(As a means of visualizing the above game, draw a straight line on a piece of paper, and mark $0,1,2,3,\ldots$ on it. Imagine yourself as player $A$. Then, according to the game, you start from the integer $a$ and at each step either move one integer forward with probability $p$ or move one integer backward with probability $q$. Such a movement is known as a \textbf{one-dimensional random walk}. The game ends when you have reached either $0$ (which is when your opponent $B$ has won) or $a+b$ (which is when you have won))}.

Assume that $p=q=0.5$. Let 
\begin{equation*}
A[k]:=P(A\text{ goes on to win the game, when his current earnings is }\$k).
\end{equation*}
\begin{enumerate}
	\item Evaluate $A[{0}]$ and $A[{a+b}]$.
	\item Express $A[k]$ in terms of $A[k-1]$ and $A[k+1]$.
	\item Solve the difference equation obtained in part $(b)$ above using the initial conditions in part $(a)$ to find a closed form expression for $A[k]$.
	\item What is the probability that $A$ ruins $B$?
\end{enumerate}

%\item Given two coins, suppose that coin $ 1 $ has probability $ 0.7 $ of coming up heads and coin $ 2 $
%has probability $ 0.6 $ of coming up heads. If we have come up with heads
%on a day, then next day we use coin $ 1 $. If we have come up with tails
%on a day, then next day we use coin $ 2 $. On day zero we pick one of the
%coins at random. What are the chances that on day $ 3 $ we flip coin $ 1 $?

%\item Three white and three black balls are distributed in two urns in such
%a way that each contains three balls. The state of the system is the
%number of white balls in the first urn. At each step we draw at random
%one ball from each urn and interchange their positions â€“ that is, the
%ball drawn from first urn goes to the second urn and vice versa. Let
%$ X_n $ denote the state of the system after the $ n^{th} $ step. 
%\begin{enumerate}
%	\item Explain why $ (X_n)_{n\geq 1} $
%	is a Markov chain. What is its state space?
%	\item Calculate the transition probability matrix
%\end{enumerate} 

\item Suppose there are $n$ papers in a drawer. You draw a paper and sign it, and  then, instead of filing it away, you place the paper back into the drawer. If any paper is equally likely to be drawn each time, independent of all other draws, what is the expected number of papers that you will draw before signing all $n$ papers? You may leave your answer in the form of a summation.
\end{enumerate}
\end{document}

% !TEX spellcheck = en_US
% !TEX spellcheck = LaTeX
\documentclass[a4paper,10pt,english]{article}
\input{header}
\title{Lecture 19: Bernoulli Processes}
\author{}

\begin{document}
\maketitle

\section{Construction of Probability Space}
Consider an experiment, where an infinite sequence of trials is conducted. 
Each trial has two possible outcomes, success or failure, denoted by $S$ and $F$ respectively.
Any outcome of the experiment is an infinite sequence of successes and failures, e.g.
\eq{
\omega = (S, F, F, S, F, S, \dots).
}
The collection of all possible outcomes of this experiment will be our sample space $\Omega = \{S,F\}^{\N}$. 
The $i$th projection of an outcome sequence $\omega \in \Omega$ is denoted by $\omega_i \in \{S,F\}$. 
We consider a $\sigma$-algebra $\sF$ on this space generated by all finite subsets of the sample space $\Omega$. 
\eq{
\sF = \sigma(\{\omega \in \Omega:  \omega_i \in \{S,F\}, \forall i \in I \subset \N \text{ for finite } I \}).
}
We further assume that each trial is independent and identically distributed, with common distribution of a single trial 
\meq{2}{
&P\{\omega_i = S\} = p, &&P\{\omega_i = F\} = q \triangleq 1-p.
}
This assumption completely characterizes the probability measure over all elements of the $\sigma$-algebra $\sF$. 
For $a \in \sF$ and the number of successes $n = |\{i \in I: a_i = S\}|$ in $I$, 
\eq{
P(a) = \prod_{i \in I}\E 1\{\omega_i = a_i\} = \prod_{i \in I: \omega_i = S}\E 1\{\omega_i = S\} \prod_{i \in I: \omega_i = F}\E 1\{\omega_i = F\} = p^nq^{|I|-n}.
}
Hence, we have completely characterized the probability space $(\Omega, \sF, P)$. 
Further, we define a discrete random process $X : \Omega \to \{0,1\}^\N$ such that 
\eq{
X_n(\omega) = 1\{\omega_n = S\}.
}
Since, each trial of the experiment is \emph{iid}, so is each $X_n$. 
\section{Bernoulli Processes}
For a probability space $(\Omega, \sF, P)$, a discrete process $X = \{X_n(\omega): n \in \N\}$ taking value in $\{0,1\}^{\N}$ is a \textbf{Bernoulli Process} 
with success probability $p = \E X_n$ if $\{X_n: n \in \N\}$ are \emph{iid} with common distribution $P\{X_n = 1\} = p$ and $P\{X_n = 0\} = q$. 
\begin{shaded*}
\begin{exmp} Examples of Bernoulli processes. 
\begin{enumerate}[i\_]
\item For products manufactured in an assembly line, $X_n$ indicates the event of $n$th product being defective. 
\item At a fork on the road, $X_n$ indicates the event of $n$th vehicle electing to go left on the fork. 
\end{enumerate}
\end{exmp}
\end{shaded*} 
Let $n(x_S) \triangleq |\{i \in S: 0 \leq x_i < 1\}|$, then the finite dimensional distribution of $X(\omega)$ is given by
\eq{
F_S(x_S) = \prod_{i \in S}P\{X_i \leq x_i\} = q^{n(x_S)}.
}
The mean, correlation, and covariance functions are given by
\begin{xalignat*}{5}
&m_X = \E X_n = p,&&R_X = \E X_n X_m = p^2, &&C_X = \E(X_n - p)(X_m-p) = 0.
\end{xalignat*}

\section{Number of Successes}
For the above experiment, let $N_n$ denote the number of successes in first $n$ trials. 
Then, we have 
\eq{
N_n(\omega) = \sum_{i=1}^{n}1\{\omega_i = S\} = \sum_{i=1}^{n}X_i(\omega). 
}
The discrete process $\{N_n (\omega) : n\in \N\}$ is a stochastic process that takes discrete values in $\N_0$. 
In particular, $N_n \in \{0, \dots, n\}$, i.e. the set of all outcomes is index dependent. 
Further, $N_n \geq 0$ for all $n$ and is a non-decreasing process, since $N_{n} = N_{n-1} + 1\{\omega_n = S\}$. 
\begin{shaded*}
\begin{exmp}
Example of discrete counting processes. 
\begin{enumerate}[i\_]
\item For products manufactured in an assembly line, $N_n$ indicates the number of defective products in the first $n$ manufactured. 
\item At a fork on the road, $N_n$ indicates the number of vehicles that turned left for first $n$ vehicles that arrived at the fork.  
\end{enumerate}
\end{exmp}
\end{shaded*} 
We can characterize the moments of this stochastic process
\meq{2}{
&m_N(n) = \E X_n = np,&&\Var{N_n} = \sum_{i=1}^{n}\Var{X_i} = npq. %\E (N_n- np)^2 = \E \sum_{i \neq j}X_i(\omega)X_j(\omega) + \E\sum_{i=1}^{n}X_i^2(\omega) - n^2p^2 = n(n-1)p^2 + np = npq. %, &&C_X = \E(X_n - p)(X_m-p) = 0.
}
Clearly, this process is not stationary since the first moment is index dependent. 
In the next lemma, we try to characterize the distribution of random variable $N_n$. 
\begin{lem} 
We can write the following recursion for $P_n(k) \triangleq P\{N_n(\omega) = k\}$, for all $n,k \in \N$
\eq{
P_{n+1}(k) = pP_{n}(k-1) + qP_{n}(k). 
}
\end{lem}
\begin{proof}
We can write using the disjoint union of probability events,  
\eq{
P\{N_{n+1} = k\} = P\{N_{n+1} = k, N_{n} = k\} +  P\{N_{n+1} = k, N_{n} = k-1\}.
}
Since $\{N_{n+1} = k, N_{n} = j\} = \{X_{n+1} = k-j, N_{n} = j\}$, from independence of Bernoulli process $X$ we have
\eq{
P\{N_{n+1} = k\} = P\{X_{n+1} = 0\}P\{N_n = k\} + P\{X_{n+1} = 1\}P\{N_n = k-1\}.
}
Result follows from definition of $P_n(k)$. 
\end{proof}
\begin{thm} The distribution of number of successes $N_n$ in first $n$ trials of a Bernoulli process is given by a Binomial $(n,p)$ distribution 
\eq{
P_n(k) = \binom{n}{k}p^kq^{(n-k)}.
}
\end{thm}
\begin{proof} 
It follows from induction. 
\end{proof}
\begin{cor} 
The stochastic process $\{N_n: n \in \N\}$ has stationary and independent increments.
\end{cor}
\begin{proof}
We can look at one increment 
\eq{
N_{m+n}-N_m = \sum_{i = 1}^{n}X_{i+m}.
}
This increment is a function of $(X_{m+1}, \dots, X_{m+n})$ and hence independent of $(X_1, \dots, X_m)$. 
The random variable $N_m$ depends solely on $(X_1, \dots, X_m)$ and hence the independence follows. 
Stationarity follows from the fact that the Bernoulli process $X$ is iid and $N_{m+n}-N_m$ is sum of $n$ iid Bernoulli random variables, 
and hence has a Binomial $(n,p)$ distribution identical to that of $N_n$. 
\end{proof}



\section{Stopping Times}
Let $(\Omega, \sF, P)$ be a probability space, and $\cF = (\sF_t: t \in T)$ be a filtration on this probability space for an ordered index set $T$.   
A random variable $\tau \in \sF$ is called a \textbf{stopping time} with respect to this filtration if the event $\{\tau \leq t\} \in \sF_t$. 

Let $\sF_t = \sigma(X_s, s \le t)$ for a random process $X = (X_t : t \in T)$. 
We can consider the ordered index set $T$ as a time sequence. 
Intuitively, if we observe the process $X$ sequentially, then the event $\{\tau \le t\}$ can be completely determined by the observation $(X_s, s \le t)$ till time $t$. 
%denotes a stopping time for the process $X$. 
%Then, we have stopped after observing, $(X_s, s \le \tau)$, and before observing $(X_s, s > \tau)$.  
The intuition behind a stopping time is that it's realization is determined by the past and present events but not by future events. 
\begin{shaded*}
\begin{exmp} Examples of stopping times.
\begin{enumerate}
\item For instance, while traveling on the bus, the random variable measuring ``time until bus crosses next stop after Majestic" is a stopping time as it's value is determined by events before it happens. 
On the other hand ``time until bus crosses the stop before Majestic'' would not be a stopping time  in the same context. 
This is because we have to cross this stop, reach Majestic and then realize we have crossed that point. 
%\item Consider $X_n \in \{0,1\}$ \textit{iid} Bernoulli$(1/2)$. Then $N = \min \{n \in \N:\quad \sum_{i=1}^n X_i = 1\}$ is a stopping time. 
%For instance, $\Pr\{N=2\} = \Pr\{X_1=0,X_2=1\}$ and hence $N$ is a stopping time by definition. 
\item Let $(N_n: n \in \N)$ be the number of successes for an \emph{iid} Bernoulli process $X$, then $T_k \triangleq \min\{n \in \N: N_n = k\}$ is a stopping time. 
%\item Let $S$ be a one-dimensional integer random walk with unit steps. 
%% \textbf{Random walk:} 
%% Consider $X_n$ \textit{iid} bivariate random variables with 
%%\eq{
%%\Pr\{X_n = 1\} = \Pr\{X_n = -1\} = \frac{1}{2}. 
%%}
%Then $\tau_i \triangleq \min \{n \in \N: S_n= i\}$ is a stopping time.
\end{enumerate}
\end{exmp}
\end{shaded*}
For the special case when $T = \N$ is a countable ordered index set, then stopping time can be defined as a random variable $N$ taking countably many values in $\N \cup \{\infty\}$ if for each $n \in \N$, we have the event $\{N = n\} \in \sF_n$.  

\subsection{Properties of stopping time} 

%Let the index set $T$ be separable, and 
\begin{lem}
Let $\tau_1,\tau_2$ be two stopping times with respect to filtration $(\sF_t: t \in T)$.  
Then the following hold true. 
\begin{enumerate}[i\_]
\item $\min \{\tau_1,\tau_2\} $ is a stopping time. 
\item If $T$ is countable, then $\tau_1+\tau_2$ is a stopping time.
\end{enumerate}
\end{lem}
\begin{proof}
Let $\cF = (\sF_t : t \in T)$ be a filtration, and $\tau_1,\tau_2$ associated stopping times. 
\begin{enumerate}[i\_]
\item Result follows since the event $\{ \min \{ \tau_1,\tau_2\} > t\} = \{\tau_1 > t\} \cap \{\tau_2 > t\} \in \sF_t$. 
%\eq{
%\{\tau_1\wedge\tau_2 > t\} = \{\tau_1 > t\} \cap \{\tau_2 > t\} \in \sF_t.
%}
%The result follows since the events $\{N_1 > n\}$ and $\{N_2 > n\}$ depend solely on $\{X_1, \dots, X_n\}$. 
\item It suffices to show that the event $\{\tau_1+\tau_2 \leq  t\} \in \sF_t$ for $T = \N$. 
To this end, we observe that 
\eq{
\{\tau_1 + \tau_2 \le n\} = \bigcup_{k \in \N}\{\tau_1 \le n - m, \tau_2 \le m\} \in \sF_n.
}
%Result follows since the events $\{\tau_1 \leq t -s \} \in \sF_{t-s} \subseteq \sF_{t}$ and $\{\tau_2 \leq s\} \subseteq \sF_s \subseteq \sF_t$. 
\end{enumerate}
\end{proof}

\subsection{Stopping time $\sigma$-algebra}

For a stopping time $\tau: \Omega \to \R_+$ adapted to the filtration $\cF$, 
the \textbf{stopping time $\sigma$-algebra} is defined as 
\eq{
\sF_{\tau} \triangleq \{A \in \sF:  A \cap \{\tau \le t\} \in \sF_t, \forall t \ge 0\}.
}
One can check that $\sF_{\tau}$ is indeed a $\sigma$-algebra. 
Further, $\sF_{\tau}$ has information up to the random time $\tau$. 
\begin{lem} 
Let $\tau, \tau_1, \tau_2$ be stopping times adapted to a filtration $\cF$. 
Then, the following are true. 
\begin{enumerate}[i\_]
\item $\tau \in \sF_{\tau}$.
\item If $\tau_1 \le \tau_2$ almost surely, then $\sF_{\tau_1} \subseteq \sF_{\tau_2}$. 
\end{enumerate}
\end{lem}
\begin{proof}
\end{proof}

\subsection{Strong Markov property}
Let $X$ be a real valued Markov process adapted to a filtration $\cF$. 
Let $\tau$ be an almost surely finite stopping time with respect to to this filtration, 
then the process $X$ is called \textbf{strongly Markov} if for all $x \in \R$ and $t > 0$, we have 
\eq{
P(\{X_{t+\tau} \le x\} |\sF_{\tau}) = P(\{X_{t+\tau} \le x\} |\sigma(X_{\tau})).
}

\begin{lem} 
Let $(X_t: t \in T)$ be any Markov process adapted to filtration $(\sF_t: t \in T)$. 
For any stopping time $\tau$ with respect to this filtration that takes only countably many values, 
Markov process $X$ is strongly Markov at this stopping time $\tau$. 
\end{lem}
\begin{proof}
\end{proof}

\begin{cor}
Any Markov process on countable index set $T$ is strongly Markov. 
\end{cor}


\section{Random Walk}
Let $X = (X_n \in \R^d: n \in \N)$ be an \emph{iid} random sequence. 
Let $S_0 = 0$ and $S_n \triangleq \sum_{i=1}^nX_i$, then the process $S = (S_n: n \in \N)$ is called a \textbf{random walk}. 
We can think of $S_n$ as the random location of a particle after $n$ steps, 
where the particle starts from origin and takes steps of size $X_i$ at the $i$th step. 

From previous section, we know following properties of random walks. 
\begin{thm} 
For a random walk $(S_n: n \in \N)$ with \emph{iid} step-size sequence $X$, the following are true. 
\begin{enumerate}[i\_]
\item The first two moments are $\E S_n = n\E X_i$ and $\Var[S_n] = n\Var[X_i]$. 
\item Random walk is non-stationary with stationary and independent increments. 
\item For any measurable set $A \in \sF$, the hitting time  $\min\{n \in N: S_n \in A\}$ of the set $A$ by random walk $S$ is a stopping time adapted to the natural filtration $\cF = (\sF_n = \sigma(X_i, i \le n): n \in \N)$.
\end{enumerate}
\end{thm}

When $X$ is a Bernoulli sequence, with $P\{X_i = 1\} = p = 1 - P\{X_i = -1\}$, 
the one dimensional random walk $S$ is an integer valued random sequence with unit step-size. 
\begin{thm} 
For a one-dimensional random walk $(S_n: n \in \N)$ with mean step-size $p-q$, the following are true. 
\begin{enumerate}[i\_]
%\item The first two moments are $\E S_n = n(p-q)$ and $\Var[S_n] = n(1 - (p-q)^2)$. 
\item Number of positive steps after $n$ steps is Binomial $(n,p)$. 
\item $P\{S_n = k\} = \binom{n}{(n+k)/2}p^{(n+k)/2}q^{(n-k)/2}$ for $n+k$ even, and $0$ otherwise. 
\end{enumerate}
\end{thm}

\begin{lem}[Wald's Lemma] 
Consider a random walk $(S_n: n \in \N)$ with \emph{iid} step-sizes $(X_n: n \in \N)$ having finite mean $\E X_1$, adapted to its natural filtration $\cF = (\sF_n: n \in \N)$. 
Let $N$ be a finite mean stopping time adapted to this filtration $\cF$. 
%Let $\{X_i:\quad i\in \N\}$ be \textit{iid} random variables with finite mean $\E[X_1]$ and let $N$ be a stopping time with respect to this set of variables, such that $\E[N] < \infty$. 
Then,
\eq{
\E S_N = \E X_1\E N.
}
\end{lem}
\begin{proof} 
From the independence of step sizes, it follows that $X_n$ is independent of $\sF_{n-1}$. 
Next we observe that $\{N \ge n\} = \{N > n-1\} \in \sF_{n-1}$, 
and hence $\E[X_n1_{\{N \ge n\}}] = \E X_n \E 1_{\{N \ge n\}}$. 
%We first show that the event $\{N \geq n\}$ is independent of $X_k$, for any $k \geq n$. 
%To this end, observe that 
%\begin{align*}
%\{N \geq k\} = \{N < k\}^c = \{N \leq k-1\}^c = \left(\bigcup_{i=1}^{k-1} \{N = i\}\right)^c. 
%\end{align*}
%Recall that $N$ is a stopping time and the event $\{N=i\}$ depends only on $\{X_1,\ldots, X_i\}$, by definition.  
%Therefore, $\{N \geq k\}$ depends only on $\{X_1,\ldots, X_{k-1}\}$, and is independent of the future and present samples. 
Therefore,
\eq{
\E\sum_{n=1}^N X_n = \E\sum_{n \in \N} X_n 1_{\{N \geq n\}} = \sum_{n \in \N} \E X_n \E\left[1_{\{N \geq n\}}\right] = \E X_1\E\left[ \sum_{n \in \N} 1_{\{N \geq n\}}\right] = \E[X_1]\E[N].
}
We exchanged limit and expectation in the above step, which is not always allowed. 
We were able to do it since the summand is positive and we apply monotone convergence theorem. 
%I'd like to point out here that in step (\ref{tricky}), you cannot always exchange infinite sums and expectations. 
%But here you can do so, because of the application of 
%Refer Ross/Wolff for more information. 
%Therefore, we can write
%	\begin{align*}
%	\sum_{n \in \N} \E\left[X_n 1_{\{N \geq n\}}\right] &= \sum_{n \in \N} \E\left[X_n\right]\E\left[ 1_{\{N \geq n\}}\right] \\
%	&= \E\left[X_1\right] \sum_{n \in \N} \Pr\{N \geq n\} \\
%	&= \E[X_1]\E[N].
%	\end{align*} 
%where the third equality follows from the fact that the expectation of a random variable being represented in terms of the \textit{ccdf} of the corresponding random variable.
\end{proof}


\todo{Edit from here.}

%\begin{prop}[Wald's Lemma for Renewal Process] \label{prop:WaldRenewal}
%	Let $\{X_n, n \in \N\}$ be \textit{iid} inter-arrival times of a renewal process $N(t)$ with $\E[X_1] < \infty$, and let $m(t) = \E[N(t)]$ be its renewal function. Then, $N(t)+1$ is a stopping time and 
%	\begin{align*}
%	\E\left[\sum_{i=1}^{N(t)+1}X_i\right] = \E[X_1][1+m(t)].
%	\end{align*}
%\end{prop}
%\begin{proof} It is easy to see that $\{N(t)+1=n\}$ depends solely on $\{X_1,\ldots,X_n\}$ from the discussion below.
%	\begin{align*}
%	\left\{N(t) + 1 = n \right\} \iff \{S_{n-1} \leq t < S_n\} \iff \left\{\sum_{i=1}^{n-1} X_i \leq t < \sum_{i=1}^{n-1} X_i + X_n\right\}.
%	\end{align*}
%	Thus $N(t)+1$ is a stopping time, and the result follows from Wald's Lemma.
%\end{proof}


\section{Times of Successes}
For the above experiment, let $T_k$ denote the trial number corresponding to $k$th success. 
Clearly, $T_k \geq k$. We can define it inductively as 
\begin{xalignat*}{3}
&T_1 = \inf\{ n \in \N: X_n(\omega) = 1\}, &&T_{k+1}(\omega) = \inf\{ n > T_{k}: X_n(\omega)  = 1\}. 
\end{xalignat*}
For example, if $X = (0, 1, 0, 1, 1, \dots)$, then $T_1 = 2, T_2 = 4, T_3 =5$ and so on.
The discrete process $\{T_k (\omega) : k \in \N\}$ is a stochastic process that takes discrete values in $\{k, k+1, \dots\}$. 
\begin{shaded*}
\begin{exmp}
Examples of renewal process. 
\begin{enumerate}[i\_]
\item For products manufactured in an assembly line, $T_k$ indicates the number of products inspected for $k$th defective product to be detected.   
\item At a fork on the road, $T_k$ indicates the number of vehicles that have arrived at fork for $k$th left turning vehicle.  
\end{enumerate}
\end{exmp}
\end{shaded*} 
We first observe the following inverse relationship between number of $n$th successful trial $T_n$, and number of successes in $n$ trials. 
\begin{lem} The following relationships hold between time of successes and number of successes 
\begin{xalignat*}{3}
&\{T_k \leq n\} = \{N_n \geq k\},&&\{T_k = n\} = \{N_{n-1} = k-1, X_n = 1\}.
\end{xalignat*}
\end{lem}
\begin{proof}
To see the first equality, we observe that $\{T_k \leq n\}$ is the set of outcomes, 
where $X_{T_1} = X_{T_2} = \dots = X_{T_k} = 1$, and $\sum_{i=1}^{T_k}X_i = k$. 
%\begin{xalignat*}{3}
%&X_{T_1} = X_{T_2} = \dots = X_{T_k} = 1, && \sum_{i=1}^{T_k}X_i = k.
%\end{xalignat*}
Hence, we can write the number of successes in first $n$ trials as 
\eq{
N_n = \sum_{i=1}^nX_i = \sum_{i > T_k}X_i + \sum_{i=1}^{T_k}X_i \geq k.
}
%Let $T_k \leq n$, that is $k$th success was seen in first $n$ trials. 
%This is, number of successes in $n$ trials is $N_n \geq k$. That is , 
%\eq{
%\{T_k \leq n\} \subseteq \{N_n \geq k\}.
%}
Conversely, we notice that we can re-write the number of trials for $i$th success as  
\eq{
T_i = \inf\{m \in \N: N_m = i\}.
}
Since $N_n$ is non-decreasing in $n$, it follows that for the set of outcome such that $\{N_n \geq k\}$, there exists $m \leq n$ such that $T_k = m \leq n$. 
%the set of outcomes $\{N_n \geq k\}$ is such that there exists an ordered set $S \subseteq [n]$ of size $|S| \geq k$, 
%such that $X_i = 1$ for all $i \in S$ and zero elsewhere. 
%We can denote first $k$ elements of $S$ by  $\{T_1, T_2, \dots, T_k\}$, and hence $T_k \leq n$. 
%Using similar arguments, we observe that if $N_n \geq k$, then it follows that $T_k \leq n$. Hence, 
%\eq{
%\{T_k \leq n\} \supseteq \{N_n \geq k\}.
%}
For the second inequality, we observe that
\eq{
\{T_k = n\} %= \{T_k \leq n, T_k > n-1\} 
= \{T_k \leq n\}\cap\{T_k \leq n-1\}^c = \{N_n \geq k\}\cap\{N_{n-1} \geq k\}^c = \{N_{n-1} = k-1, N_n = k\}. %= \{N_n \geq k, N_{n-1} < k\} = \{N_{n-1} = k-1, N_n = k\}.
}
\end{proof}

We can write the marginal distribution of process $\{T_k: k \in \N\}$ in terms of the marginal of the process $\{N_n: n \in \N\}$ as
\meq{2}{
&P\{T_k \leq n\} = \sum_{j \geq k}P_n(j) = \sum_{j=k}^{\infty}\binom{n}{j}p^jq^{(n-j)},&&P\{T_k = n\} = p\dot P_{n-1}(k-1) = \binom{n-1}{k-1}p^kq^{n-k}. 
}
Clearly, this process is not stationary since the first moment is index dependent. 
It is not straightforward to characterize moments of $T_k$ from its marginal distribution. 
\begin{lem} The time of success is a Markov chain.
\end{lem}
\begin{proof} 
By definition, $T_k$ depends only on $T_{k-1}$ and $X_i$s for $i > T_k$. 
From independence of $X_i$s, it follows that 
\eq{
P\{T_k = T_{k-1} + m | T_{k-1}, T_{k-2},\dots, T_1\} = P\{T_k - T_{k-1} = m |T_{k-1}\} = q^{m-1}p1\{m > 0\}.
}
\end{proof}
\begin{cor} The time of success process $\{T_k: k \in \N\}$ has stationary and independent increments. 
\end{cor}
\begin{proof} 
From the previous lemma and the law of total probability, we see that 
\eq{
\sum_{n \in \N_0}P\{T_k - T_{k-1} = m, T_k = n\} = pq^{m-1}1\{m > 0\}.
}
\end{proof}
Since, the increment in time of success follows a geometric distribution with success probability $p$, 
we have mean of the increment $\E(T_{k+1} - T_k) = 1/p$, and the variance $\Var{T_{k+1}-T_k} = {q}/{p^2}$. 
%\begin{xalignat*}{3}
%&\E(T_{k+1} - T_k) = \frac{1}{p}, && \E(T_{k+1}-T_k)^2 = \frac{q}{p^2}.
%\end{xalignat*}
This implies that we can write the moments of $T_k$ as
\meq{2}{
&\E T_k = \E \sum_{i=1}^{k}(T_i - T_{i-1}) = \frac{k}{p}, && \Var{T_k} =  \Var{\sum_{i=1}^{k}(T_i - T_{i-1})} = \frac{kq}{p^2}.
}
This shows that stationary and independent increments is a powerful property of a process and makes the process characterization much simpler. 
Next, we show one additional property of this process. 
\begin{lem}
The increments of time of success process $\{T_k: k \in \N\}$ are memoryless. 
\end{lem}
\begin{proof} 
It follows from the property of a geometric distribution, that for positive integers $m,n$
\eq{
P\{T_{k+1} - T_k > m + n| T_{k+1} - T_k > m \} = \frac{P\{T_{k+1}-T_k > m+n\}}{P\{T_{k+1}-T_k > m\}} = q^{n} = P\{T_{k+1}-T_k > n\}.
}
\end{proof}


\end{document}